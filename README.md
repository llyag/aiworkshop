## Datafication of Historical Sources with AI: a Practical Workshop

The workshop is designed to introduce postgraduate students with little or no coding experience to the potential of AI for research in the humanities and social sciences. We will use Large Language Models (LLMs), such as OpenAI’s ChatGPT and Google’s Gemini, to prepare sources for analysis. Our practical examples will use historical datasets provided by the Science Museum, but the approaches are applicable across disciplines.

---

### Workshop Overview

The workshop will begin with an introductory talk on the advantages, limitations, and relevance of LLMs for research, delivered by **Dr. Federico Nanni (The Alan Turing Institute)**. This will be followed by a roundtable featuring several short presentations on the practical use of AI in historical research, offering participants diverse perspectives and examples.

---

### Roundtable Participants

- **Daniel Belteki**, Science Museum  
  *“LLM Experiments with the Science Museum Collections”*

- **Jacob Forward**, University of Cambridge  
  *“LLMs for Emotion Classification in US Presidential Speeches”*

- **Liudmila Lyagushkina**, University of Nottingham  
  *“LLM as a Research Assistant: Experimenting with Historical Classifications”*

- **Joseph Nockels**, University of Sheffield  
  *“Making the Past Readable – Advancing AI Transcription Approaches for Library Collections At-Scale”*

---

### Afternoon Practical Sessions

In the afternoon, there will be two hands-on sessions:  

1. **Session 1:**  
   Learn how to use AI to extract structured data—such as dates, biographical details, concepts, and more—from textual sources.
   

3. **Session 2:**  
   Choose between:
   - applying these methods to your own sources under the guidance of the workshop organisers and moderators, **or**
   - adapting scripts to the provided datasets.
     

